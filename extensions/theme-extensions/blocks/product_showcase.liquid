{% comment %}
  Product Showcase Theme App Extension Block
  Two-column layout: Left - Product image, Right - Text content
{% endcomment %}

<div class="product-showcase-block" {{ block.shopify_attributes }}>
  <style>
    .product-showcase-block {
      display: flex;
      align-items: center;
      gap: 2rem;
      padding: 2rem;
      margin: 1rem 0;
      max-width: 100%;
    }
    
    .product-showcase-left {
      flex: 1;
      min-width: 0;
    }
    
    .product-showcase-right {
      flex: 1;
      min-width: 0;
    }
    
    .product-image {
      width: 100%;
      height: auto;
      border-radius: 8px;
      object-fit: cover;
      max-height: 400px;
    }
    
    .placeholder-image {
      width: 100%;
      height: 300px;
      background: #f5f5f5;
      border: 2px dashed #ccc;
      border-radius: 8px;
      display: flex;
      align-items: center;
      justify-content: center;
      color: #666;
      font-size: 1rem;
      text-align: center;
    }
    
    .model-container {
      position: relative;
      width: 100%;
      height: 400px;
      border-radius: 8px;
      overflow: hidden;
      background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
    }
    
    .model-canvas {
      width: 100%;
      height: 100%;
      display: block;
      border-radius: 8px;
    }
    
    .loading-indicator {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      background: rgba(255, 255, 255, 0.9);
      backdrop-filter: blur(5px);
      color: #333;
      font-size: 14px;
      z-index: 10;
    }
    
    .spinner {
      width: 40px;
      height: 40px;
      border: 3px solid #f3f3f3;
      border-top: 3px solid #333;
      border-radius: 50%;
      animation: spin 1s linear infinite;
      margin-bottom: 10px;
    }
    
    @keyframes spin {
      0% { transform: rotate(0deg); }
      100% { transform: rotate(360deg); }
    }
    
    .fallback-image {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
    }
    
    .content-title {
      font-size: {{ block.settings.title_size }}px;
      font-weight: bold;
      color: {{ block.settings.title_color }};
      margin: 0 0 1rem 0;
      line-height: 1.2;
    }
    
    .content-subtitle {
      font-size: {{ block.settings.subtitle_size }}px;
      color: {{ block.settings.subtitle_color }};
      margin: 0 0 1.5rem 0;
      line-height: 1.4;
      font-weight: 500;
    }
    
    .content-paragraph {
      font-size: {{ block.settings.text_size }}px;
      color: {{ block.settings.text_color }};
      line-height: 1.6;
      margin: 0;
    }
    
    @media (max-width: 768px) {
      .product-showcase-block {
        flex-direction: column;
        gap: 1.5rem;
        padding: 1.5rem;
      }
      
      .product-showcase-left,
      .product-showcase-right {
        flex: none;
        width: 100%;
      }
    }
  </style>
  
  <div class="product-showcase-left">
    {% if block.settings.product != blank %}
      {% assign product = all_products[block.settings.product] %}
      
      {% if product.featured_image and block.settings.enable_3d %}
        <!-- 3D Image Container -->
        <div id="model-container-{{ block.id }}" class="model-container">
          <canvas id="model-canvas-{{ block.id }}" class="model-canvas"></canvas>
          <div id="loading-{{ block.id }}" class="loading-indicator">
            <div class="spinner"></div>
            <span>Loading 3D View...</span>
          </div>
        </div>
      {% elsif product.featured_image %}
        <img 
          src="{{ product.featured_image | image_url: width: 600 }}" 
          alt="{{ product.featured_image.alt | default: product.title }}"
          class="product-image"
          width="600"
          height="400"
          loading="lazy"
        />
      {% else %}
        <div class="placeholder-image">
          <span>{{ product.title }}<br>No image available</span>
        </div>
      {% endif %}
    {% else %}
      <div class="placeholder-image">
        <span>Select a product to display</span>
      </div>
    {% endif %}
  </div>
  
  <div class="product-showcase-right">
    {% if block.settings.title != blank %}
      <h2 class="content-title">{{ block.settings.title }}</h2>
    {% endif %}
    
    {% if block.settings.subtitle != blank %}
      <h3 class="content-subtitle">{{ block.settings.subtitle }}</h3>
    {% endif %}
    
    {% if block.settings.paragraph != blank %}
      <p class="content-paragraph">{{ block.settings.paragraph }}</p>
    {% endif %}
  </div>
</div>

<!-- Modern 3D Libraries for High-Quality Product Visualization -->
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r160/three.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.15.0/dist/tf.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl@4.15.0/dist/tf-backend-webgl.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation@0.1.1675465747/selfie_segmentation.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/@tensorflow-models/depth-estimation@0.0.6/dist/depth-estimation.min.js"></script>

<script>
// Global error handler for 3D debugging
window.addEventListener('error', function(e) {
  if (e.message.includes('THREE') || e.filename.includes('three')) {
    console.error('üö® THREE.js Error:', {
      message: e.message,
      filename: e.filename,
      lineno: e.lineno,
      colno: e.colno,
      error: e.error
    });
  }
});

// Log browser support info
console.log('üåê Browser Info:', {
  userAgent: navigator.userAgent,
  webGL: !!window.WebGLRenderingContext,
  webGL2: !!window.WebGL2RenderingContext,
  devicePixelRatio: window.devicePixelRatio
});
</script>

<script>
document.addEventListener('DOMContentLoaded', function() {
  console.log('üöÄ DOM Content Loaded - Product Showcase Block {{ block.id }}');
  console.log('üì¶ Block settings:', {
    enable_3d: {{ block.settings.enable_3d | default: false }},
    rotation_speed: {{ block.settings.rotation_speed | default: 1 }},
    model_scale: {{ block.settings.model_scale | default: 1.5 }},
    camera_distance: {{ block.settings.camera_distance | default: 3 }},
    camera_height: {{ block.settings.camera_height | default: 0 }},
    enable_bobbing: {{ block.settings.enable_bobbing | default: false }}
  });
  
  {% if block.settings.enable_3d %}
    {% if block.settings.product != blank %}
      {% assign product = all_products[block.settings.product] %}
      {% if product.featured_image %}
        console.log('‚úÖ 3D enabled with product image, initializing 3D view...');
        console.log('üñºÔ∏è Image URL:', '{{ product.featured_image | image_url: width: 600 }}');
        initializeModel{{ block.id | replace: '-', '_' }}();
      {% else %}
        console.log('‚ùå No product image available for 3D view');
      {% endif %}
    {% else %}
      console.log('‚ùå No product selected for 3D view');
    {% endif %}
  {% else %}
    console.log('‚ùå 3D view disabled, showing regular image');
  {% endif %}
});

{% if block.settings.enable_3d %}
function initializeModel{{ block.id | replace: '-', '_' }}() {
  console.log('üéØ Starting 3D image initialization for block {{ block.id }}');
  
  const container = document.getElementById('model-container-{{ block.id }}');
  const canvas = document.getElementById('model-canvas-{{ block.id }}');
  const loading = document.getElementById('loading-{{ block.id }}');
  
  console.log('üîç DOM Elements found:', {
    container: !!container,
    canvas: !!canvas,
    loading: !!loading
  });
  
  if (!container || !canvas) {
    console.error('‚ùå Required DOM elements not found!', {
      container: container,
      canvas: canvas
    });
    return;
  }
  
  console.log('üìè Container dimensions:', {
    width: container.offsetWidth,
    height: container.offsetHeight
  });
  
  // Check if Three.js is loaded
  if (typeof THREE === 'undefined') {
    console.error('‚ùå THREE.js not loaded!');
    return;
  }
  console.log('‚úÖ THREE.js loaded:', THREE.REVISION);
  
  // Scene setup
  console.log('üé¨ Creating Three.js scene...');
  const scene = new THREE.Scene();
  scene.background = new THREE.Color(0xf5f7fa);
  
  const camera = new THREE.PerspectiveCamera(75, container.offsetWidth / container.offsetHeight, 0.1, 1000);
  
  console.log('üñ•Ô∏è Setting up advanced WebGL renderer...');
  const renderer = new THREE.WebGLRenderer({ 
    canvas: canvas, 
    antialias: true, 
    alpha: true,
    powerPreference: "high-performance"
  });
  
  renderer.setSize(container.offsetWidth, container.offsetHeight);
  renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
  
  // Modern Three.js color management
  renderer.outputColorSpace = THREE.SRGBColorSpace;
  renderer.toneMapping = THREE.ACESFilmicToneMapping;
  renderer.toneMappingExposure = 1.2;
  
  // Enable shadows for photorealistic rendering
  renderer.shadowMap.enabled = true;
  renderer.shadowMap.type = THREE.PCFSoftShadowMap;
  
  console.log('‚úÖ Renderer setup complete:', {
    size: [container.offsetWidth, container.offsetHeight],
    pixelRatio: renderer.getPixelRatio()
  });
  
  // Lighting setup
  console.log('üí° Setting up lighting...');
  const ambientLight = new THREE.AmbientLight(0xffffff, 0.8);
  scene.add(ambientLight);
  
  const directionalLight = new THREE.DirectionalLight(0xffffff, 0.5);
  directionalLight.position.set(5, 5, 5);
  scene.add(directionalLight);
  console.log('‚úÖ Lighting setup complete');
  
  /**
   * Next-Generation AI-Powered 3D Product System
   * Uses modern ML models for photorealistic 3D reconstruction
   */
  class AdvancedProduct3DSystem {
    constructor(config) {
      this.blockId = config.blockId;
      this.imageUrl = config.imageUrl;
      this.settings = config.settings;
      this.scene = config.scene;
      this.camera = config.camera;
      this.loading = config.loading;
      
      // Modern AI system state
      this.aiModels = {
        depthEstimation: null,
        segmentation: null,
        tensorflow: false
      };
      
      // Quality settings for professional results
      this.quality = {
        meshResolution: 256,
        textureResolution: 1024,
        depthPrecision: 16,
        antialiasing: true
      };
      
      console.log('üöÄ AdvancedProduct3DSystem initialized for block:', this.blockId);
      console.log('‚öôÔ∏è Configuration:', config);
    }
    
    async initialize() {
      console.log('üöÄ Starting AI-powered 3D system initialization...');
      
      try {
        // Step 1: Initialize AI models
        await this._initializeAIModels();
        
        // Step 2: Load and preprocess image
        const image = await this._loadImage();
        
        // Step 3: AI-powered background removal
        const segmentedImage = await this._aiBackgroundRemoval(image);
        
        // Step 4: Neural depth estimation
        const depthMap = await this._neuralDepthEstimation(segmentedImage);
        
        // Step 5: Generate photorealistic 3D mesh
        const mesh = await this._generatePhotorealisticMesh(segmentedImage, depthMap);
        
        // Step 6: Configure advanced scene
        this._configureAdvancedScene(mesh);
        
        console.log('‚úÖ AI-powered 3D system initialization complete');
        return mesh;
        
      } catch (error) {
        console.error('‚ùå AI 3D system initialization failed:', error);
        // Fallback to simplified 3D if AI fails
        return this._generateFallback3D();
      }
    }
    
    async _initializeAIModels() {
      console.log('üß† Initializing AI models for photorealistic 3D...');
      
      // Check TensorFlow.js
      if (typeof tf === 'undefined') {
        throw new Error('TensorFlow.js is required for AI-powered 3D');
      }
      
      await tf.ready();
      this.aiModels.tensorflow = true;
      console.log('‚úÖ TensorFlow.js ready:', tf.version);
      
      try {
        // Initialize depth estimation model
        if (typeof depthEstimation !== 'undefined') {
          console.log('üî¨ Loading MiDaS depth estimation model...');
          this.aiModels.depthEstimation = await depthEstimation.createEstimator(
            depthEstimation.SupportedModels.ARPortraitDepth,
            {
              runtime: 'tfjs',
              modelUrl: 'https://tfhub.dev/tensorflow/tfjs-model/midas/v2_1_small/1/default/1'
            }
          );
          console.log('‚úÖ Depth estimation model loaded');
        }
      } catch (error) {
        console.warn('‚ö†Ô∏è Advanced depth model unavailable, using fallback:', error.message);
      }
      
      try {
        // Initialize segmentation model
        if (typeof SelfieSegmentation !== 'undefined') {
          console.log('‚úÇÔ∏è Loading MediaPipe segmentation model...');
          this.aiModels.segmentation = new SelfieSegmentation({
            locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation@0.1.1675465747/${file}`
          });
          
          await new Promise((resolve, reject) => {
            this.aiModels.segmentation.setOptions({
              modelSelection: 1, // Use general model for better object segmentation
              selfieMode: false
            });
            this.aiModels.segmentation.onResults(() => resolve());
            setTimeout(() => reject(new Error('Segmentation model timeout')), 10000);
          });
          
          console.log('‚úÖ Segmentation model loaded');
        }
      } catch (error) {
        console.warn('‚ö†Ô∏è Advanced segmentation unavailable, using fallback:', error.message);
      }
      
      console.log('üìä AI Models status:', {
        tensorflow: this.aiModels.tensorflow,
        depthEstimation: !!this.aiModels.depthEstimation,
        segmentation: !!this.aiModels.segmentation
      });
    }
    
    async _loadImage() {
      console.log('üì∑ Loading image:', this.imageUrl);
      
      return new Promise((resolve, reject) => {
        const img = new Image();
        img.crossOrigin = 'anonymous';
        
        img.onload = () => {
          console.log('‚úÖ Image loaded:', {
            width: img.width,
            height: img.height,
            aspectRatio: (img.width / img.height).toFixed(2)
          });
          resolve(img);
        };
        
        img.onerror = () => {
          const error = new Error(`Failed to load image: ${this.imageUrl}`);
          console.error('‚ùå Image loading failed:', error);
          reject(error);
        };
        
        img.src = this.imageUrl;
      });
    }
    
    async _aiBackgroundRemoval(image) {
      console.log('‚úÇÔ∏è AI-powered background removal...');
      
      if (this.aiModels.segmentation) {
        try {
          return await this._mediaPipeSegmentation(image);
        } catch (error) {
          console.warn('‚ö†Ô∏è MediaPipe segmentation failed:', error.message);
        }
      }
      
      // Fallback to advanced edge-based segmentation
      return this._advancedEdgeSegmentation(image);
    }
    
    async _mediaPipeSegmentation(image) {
      console.log('ü§ñ Using MediaPipe AI segmentation...');
      
      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');
      canvas.width = image.width;
      canvas.height = image.height;
      ctx.drawImage(image, 0, 0);
      
      return new Promise((resolve, reject) => {
        this.aiModels.segmentation.onResults((results) => {
          try {
            const outputCanvas = document.createElement('canvas');
            const outputCtx = outputCanvas.getContext('2d');
            outputCanvas.width = canvas.width;
            outputCanvas.height = canvas.height;
            
            // Apply segmentation mask
            outputCtx.globalCompositeOperation = 'source-over';
            outputCtx.drawImage(results.segmentationMask, 0, 0);
            
            outputCtx.globalCompositeOperation = 'source-in';
            outputCtx.drawImage(image, 0, 0);
            
            console.log('‚úÖ AI segmentation complete');
            resolve(outputCanvas.toDataURL());
          } catch (error) {
            reject(error);
          }
        });
        
        this.aiModels.segmentation.send({ image: canvas });
        setTimeout(() => reject(new Error('Segmentation timeout')), 15000);
      });
    }
    
    async _neuralDepthEstimation(image) {
      console.log('üß† Neural depth estimation...');
      
      if (this.aiModels.depthEstimation) {
        try {
          return await this._midasDepthEstimation(image);
        } catch (error) {
          console.warn('‚ö†Ô∏è MiDaS depth estimation failed:', error.message);
        }
      }
      
      // Fallback to advanced procedural depth
      return this._advancedProceduralDepth(image);
    }
    
    async _midasDepthEstimation(imageDataUrl) {
      console.log('üî¨ Using MiDaS neural depth estimation...');
      
      const img = await this._createImageFromDataUrl(imageDataUrl);
      const tensor = tf.browser.fromPixels(img);
      
      try {
        // Preprocess for MiDaS
        const resized = tf.image.resizeBilinear(tensor, [384, 384]);
        const normalized = resized.div(255.0);
        const batched = normalized.expandDims(0);
        
        // Run depth estimation
        const depthTensor = await this.aiModels.depthEstimation.estimateDepth(batched);
        
        // Post-process depth map
        const depthData = await depthTensor.data();
        
        // Cleanup tensors
        tensor.dispose();
        resized.dispose();
        normalized.dispose();
        batched.dispose();
        depthTensor.dispose();
        
        console.log('‚úÖ Neural depth estimation complete');
        
        return {
          data: depthData,
          width: 384,
          height: 384
        };
        
      } catch (error) {
        tensor.dispose();
        throw error;
      }
    }
    
    async _removeBackground(image) {
      console.log('üé® Removing background...');
      
      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');
      canvas.width = image.width;
      canvas.height = image.height;
      ctx.drawImage(image, 0, 0);
      
      const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
      const data = imageData.data;
      
      // Smart corner detection for background color
      const corners = this._getCornerColors(data, canvas.width, canvas.height);
      const backgroundColor = this._calculateBackgroundColor(corners);
      
      console.log('üéØ Detected background color:', backgroundColor);
      
      // Remove background with configurable sensitivity
      const threshold = this.settings.bgRemovalSensitivity * 10;
      let removedPixels = 0;
      
      for (let i = 0; i < data.length; i += 4) {
        const pixel = [data[i], data[i + 1], data[i + 2]];
        const distance = this._colorDistance(pixel, backgroundColor);
        
        if (distance < threshold) {
          data[i + 3] = 0; // Make transparent
          removedPixels++;
        }
      }
      
      ctx.putImageData(imageData, 0, 0);
      
      console.log('üìä Background removal stats:', {
        totalPixels: data.length / 4,
        removedPixels: removedPixels,
        removalPercentage: ((removedPixels / (data.length / 4)) * 100).toFixed(1) + '%'
      });
      
      return canvas.toDataURL();
    }
    
    _getCornerColors(data, width, height) {
      return [
        [data[0], data[1], data[2]], // top-left
        [data[(width - 1) * 4], data[(width - 1) * 4 + 1], data[(width - 1) * 4 + 2]], // top-right
        [data[((height - 1) * width) * 4], data[((height - 1) * width) * 4 + 1], data[((height - 1) * width) * 4 + 2]], // bottom-left
        [data[((height - 1) * width + (width - 1)) * 4], data[((height - 1) * width + (width - 1)) * 4 + 1], data[((height - 1) * width + (width - 1)) * 4 + 2]] // bottom-right
      ];
    }
    
    _calculateBackgroundColor(corners) {
      return [
        Math.round(corners.reduce((sum, corner) => sum + corner[0], 0) / corners.length),
        Math.round(corners.reduce((sum, corner) => sum + corner[1], 0) / corners.length),
        Math.round(corners.reduce((sum, corner) => sum + corner[2], 0) / corners.length)
      ];
    }
    
    _colorDistance(color1, color2) {
      return Math.sqrt(
        Math.pow(color1[0] - color2[0], 2) +
        Math.pow(color1[1] - color2[1], 2) +
        Math.pow(color1[2] - color2[2], 2)
      );
    }
    
    async _generateDepthMap(imageDataUrl) {
      console.log('üß† Generating professional depth map...');
      
      // Try proven computer vision approaches
      if (this.dependencies.opencv) {
        try {
          console.log('üéØ Using OpenCV computer vision depth...');
          const depthMap = await this._generateOpenCVDepth(imageDataUrl);
          if (depthMap) return depthMap;
        } catch (error) {
          console.warn('‚ö†Ô∏è OpenCV failed:', error.message);
        }
      }
      
      if (this.dependencies.tensorflow) {
        try {
          console.log('üî¨ Using TensorFlow advanced depth...');
          const depthMap = await this._generateTensorFlowDepth(imageDataUrl);
          if (depthMap) return depthMap;
        } catch (error) {
          console.warn('‚ö†Ô∏è TensorFlow failed:', error.message);
        }
      }
      
      // Professional procedural depth
      console.log('üé® Using professional procedural depth...');
      return this._generateProfessionalDepth(imageDataUrl);
    }
    
    async _generateOpenCVDepth(imageDataUrl) {
      console.log('üéØ OpenCV computer vision depth...');
      
      const img = await this._createImageFromDataUrl(imageDataUrl);
      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');
      canvas.width = img.width;
      canvas.height = img.height;
      ctx.drawImage(img, 0, 0);
      
      // Use OpenCV for advanced computer vision
      const src = cv.imread(canvas);
      const gray = new cv.Mat();
      const edges = new cv.Mat();
      const depth = new cv.Mat();
      
      // Convert to grayscale
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
      
      // Advanced edge detection
      cv.Canny(gray, edges, 50, 150, 3, false);
      
      // Distance transform for depth
      cv.distanceTransform(edges, depth, cv.DIST_L2, cv.DIST_MASK_PRECISE);
      
      // Normalize and invert
      cv.normalize(depth, depth, 0, 1, cv.NORM_MINMAX);
      
      // Convert to depth data
      const depthData = new Float32Array(depth.data64F);
      
      // Cleanup
      src.delete();
      gray.delete(); 
      edges.delete();
      depth.delete();
      
      console.log('‚úÖ OpenCV depth complete');
      
      return {
        data: depthData,
        width: img.width,
        height: img.height
      };
    }
    
    async _generateTensorFlowDepth(imageDataUrl) {
      console.log('üî¨ TensorFlow advanced depth...');
      
      const img = await this._createImageFromDataUrl(imageDataUrl);
      const tensor = tf.browser.fromPixels(img);
      
      try {
        // Multi-scale edge detection for depth
        const grayscale = tensor.mean(2);
        
        // Gaussian blur for noise reduction
        const blurred = tf.conv2d(
          grayscale.expandDims(0).expandDims(-1),
          tf.tensor4d([[[[1/16]], [[2/16]], [[1/16]]], 
                      [[[2/16]], [[4/16]], [[2/16]]], 
                      [[[1/16]], [[2/16]], [[1/16]]]], [3, 3, 1, 1]),
          1, 'same'
        );
        
        // Sobel operators for gradient detection
        const sobelX = tf.conv2d(blurred, 
          tf.tensor4d([[[[-1]], [[0]], [[1]]], 
                      [[[-2]], [[0]], [[2]]], 
                      [[[-1]], [[0]], [[1]]]], [3, 3, 1, 1]), 1, 'same');
        
        const sobelY = tf.conv2d(blurred,
          tf.tensor4d([[[[-1]], [[-2]], [[-1]]], 
                      [[[0]], [[0]], [[0]]], 
                      [[[1]], [[2]], [[1]]]], [3, 3, 1, 1]), 1, 'same');
        
        // Gradient magnitude
        const magnitude = tf.sqrt(tf.add(tf.square(sobelX), tf.square(sobelY)));
        
        // Convert gradient to depth (invert so edges are valleys)
        const normalized = tf.div(magnitude, tf.max(magnitude));
        const inverted = tf.sub(1, normalized);
        
        // Apply Gaussian for smoothness
        const smoothed = tf.conv2d(inverted,
          tf.tensor4d([[[[1/9]], [[1/9]], [[1/9]]], 
                      [[[1/9]], [[1/9]], [[1/9]]], 
                      [[[1/9]], [[1/9]], [[1/9]]]], [3, 3, 1, 1]), 1, 'same');
        
        const depthData = await smoothed.squeeze().data();
        
        // Cleanup
        tensor.dispose();
        grayscale.dispose();
        blurred.dispose();
        sobelX.dispose();
        sobelY.dispose();
        magnitude.dispose();
        normalized.dispose();
        inverted.dispose();
        smoothed.dispose();
        
        console.log('‚úÖ TensorFlow advanced depth complete');
        
        return {
          data: depthData,
          width: img.width,
          height: img.height
        };
        
      } catch (error) {
        tensor.dispose();
        throw error;
      }
    }
    
    async _generateProfessionalDepth(imageDataUrl) {
      console.log('üé® Generating professional procedural depth...');
      
      const img = await this._createImageFromDataUrl(imageDataUrl);
      
      // Use smaller resolution for depth map to prevent memory issues
      const maxResolution = 128;
      const scale = Math.min(maxResolution / img.width, maxResolution / img.height);
      const depthWidth = Math.floor(img.width * scale);
      const depthHeight = Math.floor(img.height * scale);
      
      console.log('üìê Depth map resolution:', {
        original: `${img.width}x${img.height}`,
        depth: `${depthWidth}x${depthHeight}`,
        scale: scale.toFixed(3)
      });
      
      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');
      canvas.width = depthWidth;
      canvas.height = depthHeight;
      
      // Draw scaled image
      ctx.drawImage(img, 0, 0, depthWidth, depthHeight);
      
      const imageData = ctx.getImageData(0, 0, depthWidth, depthHeight);
      const { data } = imageData;
      const totalPixels = depthWidth * depthHeight;
      const depthData = new Float32Array(totalPixels);
      
      const centerX = depthWidth / 2;
      const centerY = depthHeight / 2;
      const maxDistance = Math.sqrt(centerX * centerX + centerY * centerY);
      
      let minDepth = 1;
      let maxDepth = 0;
      let processedPixels = 0;
      
      // Process in chunks to prevent stack overflow
      const chunkSize = 1000;
      let pixelIndex = 0;
      
      const processChunk = () => {
        const endIndex = Math.min(pixelIndex + chunkSize, totalPixels);
        
        for (let i = pixelIndex; i < endIndex; i++) {
          const x = i % depthWidth;
          const y = Math.floor(i / depthWidth);
          const dataIdx = i * 4;
          
          const brightness = (data[dataIdx] + data[dataIdx + 1] + data[dataIdx + 2]) / 3;
          const alpha = data[dataIdx + 3];
          
          // Skip transparent pixels
          if (alpha === 0) {
            depthData[i] = 0;
            continue;
          }
          
          const distanceFromCenter = Math.sqrt((x - centerX) ** 2 + (y - centerY) ** 2);
          const normalizedDistance = distanceFromCenter / maxDistance;
          
          // Combine brightness and distance for depth
          const depth = (brightness / 255) * (1 - normalizedDistance * 0.3);
          depthData[i] = depth;
          
          minDepth = Math.min(minDepth, depth);
          maxDepth = Math.max(maxDepth, depth);
          processedPixels++;
        }
        
        pixelIndex = endIndex;
      };
      
      // Process all chunks
      while (pixelIndex < totalPixels) {
        processChunk();
        
        // Yield control to prevent blocking
        if (pixelIndex < totalPixels) {
          await new Promise(resolve => setTimeout(resolve, 0));
        }
      }
      
      console.log('‚úÖ Procedural depth map complete:', {
        width: depthWidth,
        height: depthHeight,
        totalPixels: totalPixels,
        processedPixels: processedPixels,
        minDepth: minDepth.toFixed(3),
        maxDepth: maxDepth.toFixed(3)
      });
      
      return {
        data: depthData,
        width: depthWidth,
        height: depthHeight
      };
    }
    
    async _generatePhotorealisticMesh(segmentedImage, depthMap) {
      console.log('üèóÔ∏è Generating photorealistic 3D mesh...');
      
      // Create high-quality volumetric mesh with AI-enhanced geometry
      return this._createAIEnhancedMesh(segmentedImage, depthMap);
    }
    
    async _createAIEnhancedMesh(texture, depthMap) {
      console.log('üéØ Creating AI-enhanced volumetric mesh...');
      
      // Use high-resolution geometry for quality
      const resolution = this.quality.meshResolution;
      const geometry = new THREE.PlaneGeometry(2, 2, resolution - 1, resolution - 1);
      
      // Apply neural-network enhanced displacement
      await this._applyNeuralDisplacement(geometry, depthMap);
      
      // Create photorealistic material with advanced shading
      const material = await this._createPhotorealisticMaterial(texture, depthMap);
      
      const mesh = new THREE.Mesh(geometry, material);
      
      // Add advanced lighting and shadows
      mesh.castShadow = true;
      mesh.receiveShadow = true;
      
      console.log('‚úÖ AI-enhanced mesh created with', resolution, 'x', resolution, 'resolution');
      
      return mesh;
    }
    
    async _applyNeuralDisplacement(geometry, depthMap) {
      console.log('üß† Applying neural displacement mapping...');
      
      const vertices = geometry.attributes.position.array;
      const depthData = depthMap.data;
      const depthWidth = depthMap.width;
      const depthHeight = depthMap.height;
      
      // Enhanced displacement with smoothing and edge preservation
      for (let i = 0; i < vertices.length; i += 3) {
        const x = (vertices[i] + 1) * 0.5;
        const y = (vertices[i + 1] + 1) * 0.5;
        
        // Multi-scale sampling for better quality
        const depth = this._sampleDepthMultiScale(depthData, x, y, depthWidth, depthHeight);
        
        // Apply sophisticated displacement with edge enhancement
        const displacement = (depth - 0.5) * 0.3; // Increased displacement for more dramatic effect
        vertices[i + 2] = displacement;
      }
      
      geometry.attributes.position.needsUpdate = true;
      geometry.computeVertexNormals();
      
      // Add additional geometry details
      geometry.computeTangents();
      
      console.log('‚úÖ Neural displacement applied');
    }
    
    async _createPhotorealisticMaterial(textureUrl, depthMap) {
      console.log('üé® Creating photorealistic material...');
      
      const textureLoader = new THREE.TextureLoader();
      
      // Load main texture with high quality settings
      const mainTexture = await new Promise((resolve) => {
        textureLoader.load(textureUrl, (texture) => {
          texture.wrapS = THREE.ClampToEdgeWrapping;
          texture.wrapT = THREE.ClampToEdgeWrapping;
          texture.minFilter = THREE.LinearMipmapLinearFilter;
          texture.magFilter = THREE.LinearFilter;
          texture.generateMipmaps = true;
          resolve(texture);
        });
      });
      
      // Create advanced normal map from depth
      const normalMap = this._createAdvancedNormalMap(depthMap);
      
      // Create roughness map for realistic surface
      const roughnessMap = this._createRoughnessMap(depthMap);
      
      // Use physically based rendering material
      const material = new THREE.MeshStandardMaterial({
        map: mainTexture,
        normalMap: normalMap,
        normalScale: new THREE.Vector2(0.5, 0.5),
        roughnessMap: roughnessMap,
        roughness: 0.3,
        metalness: 0.1,
        transparent: true,
        side: THREE.DoubleSide,
        alphaTest: 0.1,
        envMapIntensity: 0.8
      });
      
      console.log('‚úÖ Photorealistic material created');
      
      return material;
    }
    
    _createAdvancedNormalMap(depthMap) {
      console.log('üèîÔ∏è Creating advanced normal map...');
      
      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');
      canvas.width = depthMap.width;
      canvas.height = depthMap.height;
      
      const imageData = ctx.createImageData(canvas.width, canvas.height);
      const data = imageData.data;
      
      // Calculate normals from depth gradients
      for (let y = 0; y < depthMap.height; y++) {
        for (let x = 0; x < depthMap.width; x++) {
          const idx = y * depthMap.width + x;
          const pixelIdx = idx * 4;
          
          // Sample neighboring depths for gradient calculation
          const depth = depthMap.data[idx] || 0.5;
          const depthRight = depthMap.data[idx + 1] || depth;
          const depthDown = depthMap.data[idx + depthMap.width] || depth;
          
          // Calculate gradients
          const dx = (depthRight - depth) * 2;
          const dy = (depthDown - depth) * 2;
          
          // Convert to normal vector
          const normal = new THREE.Vector3(-dx, -dy, 1).normalize();
          
          // Encode normal in RGB
          data[pixelIdx] = Math.floor((normal.x + 1) * 127.5);     // R
          data[pixelIdx + 1] = Math.floor((normal.y + 1) * 127.5); // G
          data[pixelIdx + 2] = Math.floor((normal.z + 1) * 127.5); // B
          data[pixelIdx + 3] = 255;                                 // A
        }
      }
      
      ctx.putImageData(imageData, 0, 0);
      
      const texture = new THREE.CanvasTexture(canvas);
      texture.needsUpdate = true;
      
      console.log('‚úÖ Advanced normal map created');
      return texture;
    }
    
    _createRoughnessMap(depthMap) {
      console.log('‚ú® Creating surface roughness map...');
      
      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');
      canvas.width = depthMap.width;
      canvas.height = depthMap.height;
      
      const imageData = ctx.createImageData(canvas.width, canvas.height);
      const data = imageData.data;
      
      // Create roughness based on depth variation
      for (let i = 0; i < depthMap.data.length; i++) {
        const depth = depthMap.data[i];
        
        // Areas with more depth variation are rougher
        const roughness = Math.floor((1 - depth) * 255);
        
        const pixelIndex = i * 4;
        data[pixelIndex] = roughness;     // R
        data[pixelIndex + 1] = roughness; // G
        data[pixelIndex + 2] = roughness; // B
        data[pixelIndex + 3] = 255;       // A
      }
      
      ctx.putImageData(imageData, 0, 0);
      
      const texture = new THREE.CanvasTexture(canvas);
      texture.needsUpdate = true;
      
      console.log('‚úÖ Roughness map created');
      return texture;
    }
    
    _sampleDepthMultiScale(depthData, x, y, width, height) {
      // Multi-scale sampling for higher quality
      const samples = [];
      
      // Sample at different scales
      for (let scale = 1; scale <= 3; scale++) {
        const sample = this._sampleDepthBilinear(depthData, x, y, width, height);
        samples.push(sample);
      }
      
      // Weighted average with emphasis on finer details
      return samples.reduce((sum, sample, i) => sum + sample * (i + 1), 0) / samples.reduce((sum, _, i) => sum + (i + 1), 0);
    }
    
    async _generateFallback3D() {
      console.log('üîÑ Generating fallback 3D visualization...');
      
      try {
        const image = await this._loadImage();
        const simpleDepth = await this._advancedProceduralDepth(image);
        return this._createAIEnhancedMesh(this.imageUrl, simpleDepth);
      } catch (error) {
        console.error('‚ùå Fallback 3D generation failed:', error);
        return this._createSimplePlane();
      }
    }
    
    _createSimplePlane() {
      console.log('üìÑ Creating simple plane fallback...');
      
      const geometry = new THREE.PlaneGeometry(2, 2);
      const material = new THREE.MeshBasicMaterial({
        map: new THREE.TextureLoader().load(this.imageUrl),
        transparent: true,
        side: THREE.DoubleSide
      });
      
      return new THREE.Mesh(geometry, material);
    }
    
    async _createVolumetric3DObject(frontTexture, depthMap, originalImage) {
      console.log('üéØ Creating volumetric 3D object with proper depth...');
      
      // Analyze the product shape to determine best 3D representation
      const productType = await this._analyzeProductShape(originalImage);
      console.log('üîç Product analysis:', productType);
      
      let geometry, materials;
      
      switch (productType.shape) {
        case 'cylindrical':
          ({ geometry, materials } = this._createCylindricalObject(frontTexture, depthMap, productType));
          break;
        case 'rectangular':
          ({ geometry, materials } = this._createBoxObject(frontTexture, depthMap, productType));
          break;
        default:
          ({ geometry, materials } = this._createSmartVolumetricObject(frontTexture, depthMap, productType));
      }
      
      const mesh = new THREE.Mesh(geometry, materials);
      
      console.log('‚úÖ Volumetric 3D object created:', {
        shape: productType.shape,
        dimensions: productType.dimensions,
        faces: Array.isArray(materials) ? materials.length : 1
      });
      
      return mesh;
    }
    
    async _analyzeProductShape(image) {
      console.log('üîç Analyzing product shape...');
      
      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');
      canvas.width = image.width;
      canvas.height = image.height;
      ctx.drawImage(image, 0, 0);
      
      const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
      const { data, width, height } = imageData;
      
      // Find the bounding box of the non-transparent object
      let minX = width, maxX = 0, minY = height, maxY = 0;
      let objectPixels = 0;
      
      for (let y = 0; y < height; y++) {
        for (let x = 0; x < width; x++) {
          const idx = (y * width + x) * 4;
          const alpha = data[idx + 3];
          
          if (alpha > 128) { // Non-transparent pixel
            minX = Math.min(minX, x);
            maxX = Math.max(maxX, x);
            minY = Math.min(minY, y);
            maxY = Math.max(maxY, y);
            objectPixels++;
          }
        }
      }
      
      const objectWidth = maxX - minX;
      const objectHeight = maxY - minY;
      const aspectRatio = objectWidth / objectHeight;
      const fillRatio = objectPixels / (objectWidth * objectHeight);
      
      // Determine shape based on analysis
      let shape;
      if (aspectRatio > 1.3) {
        shape = 'rectangular'; // Wide objects
      } else if (aspectRatio < 0.7) {
        shape = 'rectangular'; // Tall objects
      } else if (fillRatio > 0.7) {
        shape = 'cylindrical'; // Round/filled objects
      } else {
        shape = 'complex'; // Complex shapes
      }
      
      return {
        shape: shape,
        aspectRatio: aspectRatio,
        fillRatio: fillRatio,
        dimensions: {
          width: objectWidth,
          height: objectHeight,
          centerX: (minX + maxX) / 2,
          centerY: (minY + maxY) / 2
        }
      };
    }
    
    _createCylindricalObject(frontTexture, depthMap, productType) {
      console.log('üõ¢Ô∏è Creating cylindrical object...');
      
      // Create cylinder with front texture and generated back
      const radius = 0.5;
      const height = productType.aspectRatio > 1 ? 1 : 1.5;
      const geometry = new THREE.CylinderGeometry(radius, radius, height, 32, 8);
      
      // Create a single material for now to avoid multi-material issues
      const material = new THREE.MeshPhongMaterial({
        map: new THREE.TextureLoader().load(frontTexture),
        transparent: true,
        shininess: 30,
        side: THREE.DoubleSide
      });
      
      console.log('‚úÖ Cylindrical material created');
      
      return { geometry, materials: material };
    }
    
    _createBoxObject(frontTexture, depthMap, productType) {
      console.log('üì¶ Creating box object...');
      
      const width = Math.max(1, productType.aspectRatio);
      const height = Math.max(1, 1 / productType.aspectRatio);
      const depth = 0.3; // Moderate depth
      
      const geometry = new THREE.BoxGeometry(width, height, depth);
      
      // Create a single material for now to avoid multi-material issues
      const material = new THREE.MeshPhongMaterial({
        map: new THREE.TextureLoader().load(frontTexture),
        transparent: true,
        shininess: 30,
        side: THREE.DoubleSide
      });
      
      console.log('‚úÖ Box material created');
      
      return { geometry, materials: material };
    }
    
    _createSmartVolumetricObject(frontTexture, depthMap, productType) {
      console.log('üéØ Creating AI-enhanced volumetric object...');
      
      // Create high-resolution displaced geometry using AI depth data
      const resolution = 64; // High resolution for quality
      const geometry = new THREE.PlaneGeometry(2, 2, resolution - 1, resolution - 1);
      
      // Apply AI-generated displacement
      this._applyAdvancedDisplacement(geometry, depthMap);
      
      // Create enhanced material with proper shading
      const material = new THREE.MeshPhongMaterial({
        map: new THREE.TextureLoader().load(frontTexture),
        transparent: true,
        side: THREE.DoubleSide,
        shininess: 50,
        specular: 0x222222,
        bumpMap: this._createBumpMap(depthMap),
        bumpScale: 0.05
      });
      
      console.log('‚úÖ AI-enhanced volumetric object created');
      
      return { geometry, materials: material };
    }
    
    _applyAdvancedDisplacement(geometry, depthMap) {
      console.log('üé® Applying AI displacement mapping...');
      
      const vertices = geometry.attributes.position.array;
      const depthData = depthMap.data;
      const depthWidth = depthMap.width;
      const depthHeight = depthMap.height;
      
      let minDisplacement = Infinity;
      let maxDisplacement = -Infinity;
      let displacedVertices = 0;
      
      for (let i = 0; i < vertices.length; i += 3) {
        const x = (vertices[i] + 1) * 0.5; // Convert from -1,1 to 0,1
        const y = (vertices[i + 1] + 1) * 0.5;
        
        // Sample depth value with bilinear interpolation for smoothness
        const depth = this._sampleDepthBilinear(depthData, x, y, depthWidth, depthHeight);
        
        // Apply sophisticated displacement
        const displacement = (depth - 0.5) * 0.2; // Moderate displacement
        vertices[i + 2] = displacement;
        
        minDisplacement = Math.min(minDisplacement, displacement);
        maxDisplacement = Math.max(maxDisplacement, displacement);
        if (displacement !== 0) displacedVertices++;
      }
      
      geometry.attributes.position.needsUpdate = true;
      geometry.computeVertexNormals();
      
      console.log('üìä Advanced displacement stats:', {
        vertices: vertices.length / 3,
        displacedVertices: displacedVertices,
        minDisplacement: minDisplacement.toFixed(3),
        maxDisplacement: maxDisplacement.toFixed(3),
        range: (maxDisplacement - minDisplacement).toFixed(3)
      });
    }
    
    _sampleDepthBilinear(depthData, x, y, width, height) {
      // Bilinear interpolation for smooth sampling
      const fx = x * (width - 1);
      const fy = y * (height - 1);
      
      const x0 = Math.floor(fx);
      const x1 = Math.min(x0 + 1, width - 1);
      const y0 = Math.floor(fy);
      const y1 = Math.min(y0 + 1, height - 1);
      
      const wx = fx - x0;
      const wy = fy - y0;
      
      const d00 = depthData[y0 * width + x0] || 0.5;
      const d10 = depthData[y0 * width + x1] || 0.5;
      const d01 = depthData[y1 * width + x0] || 0.5;
      const d11 = depthData[y1 * width + x1] || 0.5;
      
      const d0 = d00 * (1 - wx) + d10 * wx;
      const d1 = d01 * (1 - wx) + d11 * wx;
      
      return d0 * (1 - wy) + d1 * wy;
    }
    
    _createBumpMap(depthMap) {
      console.log('üèîÔ∏è Creating bump map from depth data...');
      
      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');
      canvas.width = depthMap.width;
      canvas.height = depthMap.height;
      
      const imageData = ctx.createImageData(canvas.width, canvas.height);
      const data = imageData.data;
      
      for (let i = 0; i < depthMap.data.length; i++) {
        const depth = depthMap.data[i];
        const intensity = Math.floor(depth * 255);
        
        const pixelIndex = i * 4;
        data[pixelIndex] = intensity;     // R
        data[pixelIndex + 1] = intensity; // G
        data[pixelIndex + 2] = intensity; // B
        data[pixelIndex + 3] = 255;       // A
      }
      
      ctx.putImageData(imageData, 0, 0);
      
      const texture = new THREE.CanvasTexture(canvas);
      texture.needsUpdate = true;
      
      console.log('‚úÖ Bump map created');
      return texture;
    }
    
    _generateBackTexture(frontTextureUrl) {
      console.log('üîÑ Generating back texture...');
      
      // Return the same texture for now to avoid async issues
      return new THREE.TextureLoader().load(frontTextureUrl);
    }
    
    _configureAdvancedScene(mesh) {
      console.log('üé¨ Configuring advanced scene with professional lighting...');
      
      // Apply scale
      mesh.scale.setScalar(this.settings.modelScale);
      this.scene.add(mesh);
      
      // Enhanced lighting setup for photorealistic rendering
      this._setupAdvancedLighting();
      
      // Position camera with better framing
      this.camera.position.z = this.settings.cameraDistance;
      this.camera.position.y = this.settings.cameraHeight;
      this.camera.lookAt(0, 0, 0);
      
      // Add environment mapping for reflections
      this._setupEnvironmentMapping();
      
      // Hide loading indicator
      if (this.loading) {
        this.loading.style.display = 'none';
      }
      
      console.log('üéØ Advanced scene configuration complete:', {
        meshScale: this.settings.modelScale,
        cameraPosition: {
          x: this.camera.position.x,
          y: this.camera.position.y,
          z: this.camera.position.z
        },
        lighting: 'advanced',
        environment: 'mapped'
      });
    }
    
    _setupAdvancedLighting() {
      console.log('üí° Setting up advanced lighting system...');
      
      // Remove existing lights
      const lightsToRemove = [];
      this.scene.traverse((child) => {
        if (child.isLight) {
          lightsToRemove.push(child);
        }
      });
      lightsToRemove.forEach(light => this.scene.remove(light));
      
      // Key light (main illumination)
      const keyLight = new THREE.DirectionalLight(0xffffff, 1.2);
      keyLight.position.set(2, 3, 4);
      keyLight.castShadow = true;
      keyLight.shadow.mapSize.width = 2048;
      keyLight.shadow.mapSize.height = 2048;
      this.scene.add(keyLight);
      
      // Fill light (soften shadows)
      const fillLight = new THREE.DirectionalLight(0xffffff, 0.4);
      fillLight.position.set(-2, 1, 2);
      this.scene.add(fillLight);
      
      // Rim light (edge definition)
      const rimLight = new THREE.DirectionalLight(0xffffff, 0.6);
      rimLight.position.set(0, 2, -3);
      this.scene.add(rimLight);
      
      // Ambient light (global illumination)
      const ambientLight = new THREE.AmbientLight(0xffffff, 0.3);
      this.scene.add(ambientLight);
      
      console.log('‚úÖ Advanced lighting system configured');
    }
    
    _setupEnvironmentMapping() {
      console.log('üåç Setting up environment mapping...');
      
      // Create a simple environment map for reflections
      const cubeRenderTarget = new THREE.WebGLCubeRenderTarget(256);
      const cubeCamera = new THREE.CubeCamera(0.1, 1000, cubeRenderTarget);
      
      // Set environment map for the scene
      this.scene.environment = cubeRenderTarget.texture;
      
      console.log('‚úÖ Environment mapping configured');
    }
    
    async _advancedEdgeSegmentation(image) {
      console.log('üîç Advanced edge-based segmentation...');
      
      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');
      canvas.width = image.width;
      canvas.height = image.height;
      ctx.drawImage(image, 0, 0);
      
      const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
      const data = imageData.data;
      
      // Advanced background detection using multiple algorithms
      const backgroundMask = this._detectBackgroundAdvanced(data, canvas.width, canvas.height);
      
      // Apply mask with edge smoothing
      for (let i = 0; i < data.length; i += 4) {
        const pixelIndex = i / 4;
        if (backgroundMask[pixelIndex]) {
          data[i + 3] = 0; // Make transparent
        } else {
          // Apply edge smoothing for better quality
          const alpha = this._calculateEdgeSmoothing(backgroundMask, pixelIndex, canvas.width, canvas.height);
          data[i + 3] = Math.floor(data[i + 3] * alpha);
        }
      }
      
      ctx.putImageData(imageData, 0, 0);
      
      console.log('‚úÖ Advanced edge segmentation complete');
      return canvas.toDataURL();
    }
    
    _detectBackgroundAdvanced(data, width, height) {
      console.log('üéØ Advanced background detection...');
      
      const mask = new Array(width * height).fill(false);
      
      // Multi-algorithm approach
      const cornerColors = this._getCornerColors(data, width, height);
      const dominantColor = this._calculateBackgroundColor(cornerColors);
      
      // Edge-based detection
      const edges = this._detectEdges(data, width, height);
      
      // Combine color and edge information
      for (let i = 0; i < data.length; i += 4) {
        const pixelIndex = i / 4;
        const x = pixelIndex % width;
        const y = Math.floor(pixelIndex / width);
        
        const pixel = [data[i], data[i + 1], data[i + 2]];
        const colorDistance = this._colorDistance(pixel, dominantColor);
        const isEdge = edges[pixelIndex];
        
        // Adaptive threshold based on position and edge information
        const threshold = this._calculateAdaptiveThreshold(x, y, width, height, isEdge);
        
        mask[pixelIndex] = colorDistance < threshold;
      }
      
      // Post-process mask with morphological operations
      return this._morphologicalCleanup(mask, width, height);
    }
    
    _detectEdges(data, width, height) {
      console.log('üîç Edge detection...');
      
      const edges = new Array(width * height).fill(false);
      
      // Sobel edge detection
      for (let y = 1; y < height - 1; y++) {
        for (let x = 1; x < width - 1; x++) {
          const idx = y * width + x;
          
          // Get surrounding pixels
          const pixels = [];
          for (let dy = -1; dy <= 1; dy++) {
            for (let dx = -1; dx <= 1; dx++) {
              const pixelIdx = ((y + dy) * width + (x + dx)) * 4;
              const gray = (data[pixelIdx] + data[pixelIdx + 1] + data[pixelIdx + 2]) / 3;
              pixels.push(gray);
            }
          }
          
          // Sobel operators
          const gx = pixels[2] + 2 * pixels[5] + pixels[8] - pixels[0] - 2 * pixels[3] - pixels[6];
          const gy = pixels[0] + 2 * pixels[1] + pixels[2] - pixels[6] - 2 * pixels[7] - pixels[8];
          
          const magnitude = Math.sqrt(gx * gx + gy * gy);
          edges[idx] = magnitude > 30; // Edge threshold
        }
      }
      
      return edges;
    }
    
    _calculateAdaptiveThreshold(x, y, width, height, isEdge) {
      const centerX = width / 2;
      const centerY = height / 2;
      const distanceFromCenter = Math.sqrt((x - centerX) ** 2 + (y - centerY) ** 2);
      const maxDistance = Math.sqrt(centerX ** 2 + centerY ** 2);
      const normalizedDistance = distanceFromCenter / maxDistance;
      
      // Base threshold
      let threshold = 30;
      
      // Increase threshold near edges (less likely to be background)
      if (normalizedDistance > 0.7) {
        threshold += 20;
      }
      
      // Decrease threshold near detected edges (more likely to be object boundary)
      if (isEdge) {
        threshold -= 15;
      }
      
      return threshold;
    }
    
    _morphologicalCleanup(mask, width, height) {
      console.log('üßπ Morphological cleanup...');
      
      const cleaned = [...mask];
      
      // Erosion followed by dilation (opening operation)
      // This removes small noise while preserving main shapes
      
      // Erosion
      for (let y = 1; y < height - 1; y++) {
        for (let x = 1; x < width - 1; x++) {
          const idx = y * width + x;
          
          // Check 3x3 neighborhood
          let allBackground = true;
          for (let dy = -1; dy <= 1 && allBackground; dy++) {
            for (let dx = -1; dx <= 1 && allBackground; dx++) {
              const neighborIdx = (y + dy) * width + (x + dx);
              if (!mask[neighborIdx]) {
                allBackground = false;
              }
            }
          }
          
          cleaned[idx] = allBackground;
        }
      }
      
      return cleaned;
    }
    
    _calculateEdgeSmoothing(mask, pixelIndex, width, height) {
      const x = pixelIndex % width;
      const y = Math.floor(pixelIndex / width);
      
      // Count background pixels in 3x3 neighborhood
      let backgroundCount = 0;
      let totalCount = 0;
      
      for (let dy = -1; dy <= 1; dy++) {
        for (let dx = -1; dx <= 1; dx++) {
          const nx = x + dx;
          const ny = y + dy;
          
          if (nx >= 0 && nx < width && ny >= 0 && ny < height) {
            const neighborIdx = ny * width + nx;
            if (mask[neighborIdx]) backgroundCount++;
            totalCount++;
          }
        }
      }
      
      // Return alpha based on background ratio
      return 1 - (backgroundCount / totalCount);
    }
    
    async _advancedProceduralDepth(image) {
      console.log('üé® Advanced procedural depth generation...');
      
      const img = await this._createImageFromDataUrl(image);
      
      // Use optimal resolution for quality vs performance
      const maxResolution = 256;
      const scale = Math.min(maxResolution / img.width, maxResolution / img.height);
      const depthWidth = Math.floor(img.width * scale);
      const depthHeight = Math.floor(img.height * scale);
      
      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');
      canvas.width = depthWidth;
      canvas.height = depthHeight;
      ctx.drawImage(img, 0, 0, depthWidth, depthHeight);
      
      const imageData = ctx.getImageData(0, 0, depthWidth, depthHeight);
      const { data } = imageData;
      const totalPixels = depthWidth * depthHeight;
      const depthData = new Float32Array(totalPixels);
      
      // Multi-factor depth calculation
      const centerX = depthWidth / 2;
      const centerY = depthHeight / 2;
      const maxDistance = Math.sqrt(centerX * centerX + centerY * centerY);
      
      for (let i = 0; i < totalPixels; i++) {
        const x = i % depthWidth;
        const y = Math.floor(i / depthWidth);
        const dataIdx = i * 4;
        
        const r = data[dataIdx];
        const g = data[dataIdx + 1];
        const b = data[dataIdx + 2];
        const alpha = data[dataIdx + 3];
        
        if (alpha === 0) {
          depthData[i] = 0;
          continue;
        }
        
        // Enhanced depth calculation
        const brightness = (r + g + b) / 3;
        const saturation = this._calculateSaturation(r, g, b);
        const distanceFromCenter = Math.sqrt((x - centerX) ** 2 + (y - centerY) ** 2);
        const normalizedDistance = distanceFromCenter / maxDistance;
        
        // Combine multiple factors for better depth
        const brightnessFactor = brightness / 255;
        const saturationFactor = saturation;
        const distanceFactor = 1 - normalizedDistance * 0.4;
        
        // Weighted combination
        const depth = (brightnessFactor * 0.6 + saturationFactor * 0.2 + distanceFactor * 0.2);
        depthData[i] = Math.max(0, Math.min(1, depth));
      }
      
      // Apply Gaussian smoothing for better quality
      const smoothedDepth = this._gaussianSmooth(depthData, depthWidth, depthHeight);
      
      console.log('‚úÖ Advanced procedural depth complete:', {
        resolution: `${depthWidth}x${depthHeight}`,
        algorithm: 'multi-factor with smoothing'
      });
      
      return {
        data: smoothedDepth,
        width: depthWidth,
        height: depthHeight
      };
    }
    
    _calculateSaturation(r, g, b) {
      const max = Math.max(r, g, b);
      const min = Math.min(r, g, b);
      return max === 0 ? 0 : (max - min) / max;
    }
    
    _gaussianSmooth(data, width, height) {
      console.log('üåä Applying Gaussian smoothing...');
      
      const smoothed = new Float32Array(data.length);
      const kernel = [
        [1/16, 2/16, 1/16],
        [2/16, 4/16, 2/16],
        [1/16, 2/16, 1/16]
      ];
      
      for (let y = 1; y < height - 1; y++) {
        for (let x = 1; x < width - 1; x++) {
          const idx = y * width + x;
          let sum = 0;
          
          for (let ky = -1; ky <= 1; ky++) {
            for (let kx = -1; kx <= 1; kx++) {
              const neighborIdx = (y + ky) * width + (x + kx);
              sum += data[neighborIdx] * kernel[ky + 1][kx + 1];
            }
          }
          
          smoothed[idx] = sum;
        }
      }
      
      // Copy edges
      for (let i = 0; i < data.length; i++) {
        const x = i % width;
        const y = Math.floor(i / width);
        
        if (x === 0 || x === width - 1 || y === 0 || y === height - 1) {
          smoothed[i] = data[i];
        }
      }
      
      return smoothed;
    }
    
    async _createImageFromDataUrl(dataUrl) {
      return new Promise((resolve, reject) => {
        const img = new Image();
        img.crossOrigin = 'anonymous';
        img.onload = () => resolve(img);
        img.onerror = reject;
        img.src = dataUrl;
      });
    }
  }
  
  // Create realistic 3D object with AI depth estimation
  console.log('üñºÔ∏è Creating realistic 3D object from product image...');
  const imageUrl = '{{ product.featured_image | image_url: width: 600 }}';
  
  // Initialize the advanced AI-powered 3D system
  const system3D = new AdvancedProduct3DSystem({
    blockId: '{{ block.id }}',
    imageUrl: imageUrl,
    settings: {
      modelScale: {{ block.settings.model_scale | default: 1.5 }},
      cameraDistance: {{ block.settings.camera_distance | default: 3 }},
      cameraHeight: {{ block.settings.camera_height | default: 0 }},
      bgRemovalSensitivity: {{ block.settings.bg_removal_sensitivity | default: 5 }}
    },
    scene: scene,
    camera: camera,
    loading: loading
  });
  
  system3D.initialize()
    .then(mesh => {
      console.log('‚úÖ 3D system initialized successfully');
      window['model_{{ block.id | replace: "-", "_" }}'] = mesh;
      animate();
    })
    .catch(error => {
      console.error('‚ùå 3D system initialization failed:', error);
      if (loading) loading.style.display = 'none';
    });
  
  // Animation loop
  let animationStarted = false;
  let clock = new THREE.Clock();
  
  function animate() {
    if (!animationStarted) {
      console.log('üé¨ Animation loop started successfully!');
      animationStarted = true;
    }
    
    requestAnimationFrame(animate);
    
    const model = window['model_{{ block.id | replace: "-", "_" }}'];
    if (model) {
      // Continuous rotation
      const rotationSpeed = {{ block.settings.rotation_speed | default: 1 }} * 0.01;
      model.rotation.y += rotationSpeed;
      
      // Optional: slight up-down bobbing
      {% if block.settings.enable_bobbing %}
        model.position.y += Math.sin(clock.getElapsedTime() * 2) * 0.01;
      {% endif %}
    }
    
    try {
      renderer.render(scene, camera);
    } catch (renderError) {
      console.error('‚ùå Render error:', renderError);
    }
  }
  
  // Handle window resize
  function handleResize() {
    console.log('üîÑ Window resize detected');
    if (!container || !camera || !renderer) {
      console.log('‚ùå Missing objects for resize');
      return;
    }
    
    const width = container.offsetWidth;
    const height = container.offsetHeight;
    
    console.log('üìè New dimensions:', { width, height });
    
    camera.aspect = width / height;
    camera.updateProjectionMatrix();
    renderer.setSize(width, height);
  }
  
  window.addEventListener('resize', handleResize);
  console.log('‚úÖ Resize listener added');
  
  // Handle visibility change for performance
  document.addEventListener('visibilitychange', function() {
    if (document.hidden) {
      console.log('‚è∏Ô∏è Tab hidden - pausing animation');
      renderer.setAnimationLoop(null);
    } else {
      console.log('‚ñ∂Ô∏è Tab visible - resuming animation');
      renderer.setAnimationLoop(animate);
    }
  });
  console.log('‚úÖ Visibility change listener added');
  
  // Cleanup function
  window.addEventListener('beforeunload', function() {
    console.log('üßπ Cleaning up 3D resources...');
    if (renderer) {
      renderer.dispose();
    }
    if (model) {
      scene.remove(model);
    }
  });
  console.log('‚úÖ Cleanup listener added');
}
{% endif %}
</script>

{% schema %}
{
  "name": "Product Showcase",
  "target": "section",
  "settings": [
    {
      "type": "product",
      "id": "product",
      "label": "Select Product"
    },
    {
      "type": "header",
      "content": "3D Display Settings"
    },
    {
      "type": "checkbox",
      "id": "enable_3d",
      "label": "Enable 3D Spinning View",
      "default": false,
      "info": "Convert the product image into a spinning 3D display"
    },
    {
      "type": "range",
      "id": "rotation_speed",
      "label": "Rotation Speed",
      "min": 0,
      "max": 5,
      "step": 1,
      "default": 1,
      "info": "How fast the model rotates (0 = no rotation, 5 = fastest)"
    },
    {
      "type": "range",
      "id": "model_scale",
      "label": "Model Scale",
      "min": 0.5,
      "max": 3.0,
      "step": 0.1,
      "default": 1.5,
      "info": "Size of the 3D model"
    },
    {
      "type": "range",
      "id": "camera_distance",
      "label": "Camera Distance",
      "min": 1,
      "max": 8,
      "step": 0.5,
      "default": 3,
      "info": "How far the camera is from the model"
    },
    {
      "type": "range",
      "id": "camera_height",
      "label": "Camera Height",
      "min": -2,
      "max": 2,
      "step": 0.2,
      "default": 0,
      "info": "Vertical position of the camera"
    },
    {
      "type": "checkbox",
      "id": "enable_bobbing",
      "label": "Enable Gentle Bobbing Animation",
      "default": false,
      "info": "Adds a subtle up-down movement to the model"
    },
    {
      "type": "select",
      "id": "object_shape",
      "label": "3D Object Shape",
      "options": [
        {
          "value": "auto",
          "label": "Auto-detect (Recommended)"
        },
        {
          "value": "cylinder",
          "label": "Cylinder (Round products)"
        },
        {
          "value": "box",
          "label": "Box (Rectangular products)"
        }
      ],
      "default": "auto",
      "info": "Choose the 3D shape that best fits your product"
    },
    {
      "type": "range",
      "id": "bg_removal_sensitivity",
      "label": "Background Removal Sensitivity",
      "min": 1,
      "max": 10,
      "step": 1,
      "default": 5,
      "info": "Higher values remove more background (1=conservative, 10=aggressive)"
    },
    {
      "type": "text",
      "id": "title",
      "label": "Title",
      "default": "Featured Product"
    },
    {
      "type": "text",
      "id": "subtitle",
      "label": "Subtitle",
      "default": "Discover something amazing"
    },
    {
      "type": "textarea",
      "id": "paragraph",
      "label": "Description",
      "default": "Add your product description here. This is a great place to highlight key features and benefits that make your product special."
    },
    {
      "type": "header",
      "content": "Title Styling"
    },
    {
      "type": "range",
      "id": "title_size",
      "label": "Title Font Size",
      "min": 16,
      "max": 48,
      "step": 2,
      "default": 32,
      "unit": "px"
    },
    {
      "type": "color",
      "id": "title_color",
      "label": "Title Color",
      "default": "#000000"
    },
    {
      "type": "header",
      "content": "Subtitle Styling"
    },
    {
      "type": "range",
      "id": "subtitle_size",
      "label": "Subtitle Font Size",
      "min": 12,
      "max": 32,
      "step": 2,
      "default": 20,
      "unit": "px"
    },
    {
      "type": "color",
      "id": "subtitle_color",
      "label": "Subtitle Color",
      "default": "#666666"
    },
    {
      "type": "header",
      "content": "Text Styling"
    },
    {
      "type": "range",
      "id": "text_size",
      "label": "Text Font Size",
      "min": 12,
      "max": 24,
      "step": 1,
      "default": 16,
      "unit": "px"
    },
    {
      "type": "color",
      "id": "text_color",
      "label": "Text Color",
      "default": "#333333"
    }
  ]
}
{% endschema %}

